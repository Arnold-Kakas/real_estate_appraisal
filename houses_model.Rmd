---
title: "houses_model"
author: "Arnold Kaka≈°"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
# Display only results in output
knitr::opts_chunk$set(echo = FALSE)

# Load pacman library for managing packages
library(pacman)

# Load and install multiple packages at once
p_load(rio, tidyverse, tidymodels, GGally, mice, vip, reticulate, skimr, spacyr)

# Prefer tidymodels package functions
tidymodels_prefer()

# specify Python
use_python("C:/Users/kakas/AppData/Local/r-miniconda", required = TRUE)
```

```{python}
# Load Python modules
import multiprocessing as mp
import pandas as pd
import spacy
import time
from googletrans import Translator
```

create and evaluate models


```{r}
# Import data
houses <- rio::import("data/houses.rds")
text <- rio::import("data/texts.rds")
```


```{r}
# Merge text to houses db
houses_merged <- houses %>%
  left_join(text, by = c("link" = "url"))
```


```{r warning=FALSE}
# Transform vectors types
houses_cleaned <- houses_merged %>%
  mutate(
    usable_area = as.numeric(usable_area),
    built_up_area = as.numeric(built_up_area),
    land_area = as.numeric(land_area)
  )
```


```{r warning=FALSE}
# impute missing values
set.seed(123)
houses_cleaned <-
  houses_cleaned %>%
  mice(m = 5, maxit = 5, method = "pmm", print = FALSE)
houses_cleaned <- complete(houses_cleaned)
```


```{r}
houses_cleaned <- houses_cleaned %>%
  filter(
    usable_area > quantile(usable_area, 0.01),
    usable_area < quantile(usable_area, 0.9),
    built_up_area < quantile(built_up_area, 0.9),
    land_area < quantile(land_area, 0.9)
  ) %>%
  mutate(
    condition = replace_na(condition, "not provided"),
    district = as_factor(district),
    municipality = as_factor(municipality),
    type = as_factor(type),
    commission_in_price = as_factor(commission_in_price)
  )
```

```{python}
# Define a function for translating text from Slovak to English
def translate_text(text):
    """
    Translates the input text from Slovak to English.

    Parameters
    ----------
    text : str
        The text to be translated.

    Returns
    -------
    str
        The translated text.
    """
    # Create a Translator object
    translator = Translator(service_urls=['translate.google.com'])
    # Translate the text and return the result
    return translator.translate(text, dest='en').text

# Apply the translate_text function to the info_text column of the houses dataframe
houses_translated['info_text_en'] = houses_cleaned['info_text'].apply(
    lambda x: translate_text(x)
)
# Wait 2 seconds before translating the next text
    time.sleep(2)

```


```{python}
# Load the Slovak language model
nlp = spacy.load("sk_core_news_sm")
```

```{r}
# Load the Slovak language model
model <- spacy_initialize(model = "xx_core_web_sm")


# Define a function to extract topics from text
extract_topics <- function(text) {
  doc <- spacy_parse(text, as_strings = TRUE)
  topics <- doc$text[doc$pos == "NOUN" | doc$pos == "PROPN"]
  return(head(topics, 10))
}

# Apply the topic extraction function to the "info_text" column
houses_topics <- houses_cleaned %>% mutate(topics = extract_topics(info_text))
```

```{r}
test <- houses_cleaned %>% 
  mutate(text_lenght = str_length(info_text))
```

```{r}
ggplot(houses_cleaned, mapping = aes(x = built_up_area)) +
  geom_boxplot()
```

```{r}
# EDA
summary(houses_cleaned)
```

```{r}
ggpairs(houses_cleaned[, c(1, 6, 7, 10, 11)], progress = FALSE)
```

```{r}
# EDA
```

```{r}

# houses_BoxCox <- recipe(houses_train, price ~ .) %>%
#   step_rm(lon, lat, lon_rotated, lat_rotated) %>%
#   step_BoxCox(all_numeric_predictors()) %>%
#   prep() %>%
#   bake(new_data = NULL)
#
# houses_log <- recipe(houses_train, price ~ .) %>%
#   step_rm(lon, lat, lon_rotated, lat_rotated) %>%
#   step_log(all_numeric_predictors()) %>%
#   prep() %>%
#   bake(new_data = NULL)
#
# houses_norm <- recipe(houses_train, price ~ .) %>%
#   step_rm(lon, lat, lon_rotated, lat_rotated) %>%
#   step_normalize(all_numeric_predictors()) %>%
#   prep() %>%
#   bake(new_data = NULL)
#
# # Plot distribution of built_up_area before and after transformations
# p1 <- ggplot(data = houses_cleaned, aes(x = built_up_area)) +
#   geom_density() +
#   ggtitle("price before transformations")
#
# p2 <- ggplot(data = houses_BoxCox, aes(x = built_up_area)) +
#   geom_density() +
#   ggtitle("price after Box-Cox transform")
#
# p3 <- ggplot(data = houses_norm, aes(x = built_up_area)) +
#   geom_density() +
#   ggtitle("price after normalization")
#
# p4 <- ggplot(data = houses_log, aes(x = built_up_area)) +
#   geom_density() +
#   ggtitle("price after log transform")
#
# (p1 + p2) / (p3 + p4)
```



```{r}
# split dataframes to train(80)/test(20)
houses_cleaned <- droplevels(houses_cleaned)
set.seed(345)
houses_train_split <- initial_split(houses_cleaned, prop = 0.8, strata = price)

houses_train <- training(houses_train_split)
houses_test <- testing(houses_train_split)

set.seed(567)
houses_train_boots <- bootstraps(houses_train, times = 25)
```

```{r}
# recipes
houses_xgboost_recipe <- recipe(houses_train, price ~ .) %>%
  step_rm(lat, lon, municipality) %>%
  step_naomit(all_nominal_predictors()) %>% 
  step_BoxCox(usable_area, built_up_area, land_area) %>%
  step_other(all_nominal_predictors(), threshold = 0.01) %>%
  step_dummy(all_nominal_predictors())
```


```{r}
# models
xgb_model <-
  boost_tree(
    trees = 1000, loss_reduction = tune(),
    tree_depth = tune(), min_n = tune(),
    mtry = tune(), sample_size = tune(),
    learn_rate = tune()
  ) %>%
  set_mode("regression") %>%
  set_engine("xgboost", nthread = 6) # use 6 cores for multithreading
```

```{r}
# workflows
houses_workflow <- workflow() %>%
  add_recipe(houses_xgboost_recipe) %>%
  add_model(xgb_model)
```

```{r}
# parameters
houses_xgboost_params <- parameters(
  trees(),
  tree_depth(), min_n(),
  finalize(mtry(), houses_train)
)
```

```{r}
# optimization
set.seed(789)
houses_xgboost_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), houses_train),
  learn_rate(),
  size = 30
)
```

```{r}
# results
houses_xgboost_res <- tune_grid(
  houses_workflow,
  resamples = houses_train_boots,
  grid = houses_xgboost_grid,
  control = control_grid(save_pred = TRUE)
)
```

```{r}
# best models
houses_best_model <- select_best(houses_xgboost_res, "rmse")
```

```{r}
# finalize models
houses_final_model <- finalize_model(xgb_model, houses_best_model)
houses_workflow <- houses_workflow %>% update_model(houses_final_model)
houses_xgb_fit <- fit(houses_workflow, data = houses_train)
```

```{r}
houses_xgb_fit %>%
  fit(data = houses_train) %>%
  pull_workflow_fit() %>%
  vip(geom = "point")
```

```{r}
houses_final_res <- last_fit(houses_xgb_fit, houses_train_split)
collect_metrics(houses_final_res)
# rsq is small, need to look for more predictors
```

```{r}
# evaluate
houses_pred <-
  predict(houses_xgb_fit, houses_test) %>%
  bind_cols(houses_test) %>%
  mutate(
    prediction = 10^.pred,
    real_price = 10^price
  )

houses_plot1 <-
  houses_pred %>%
  ggplot(aes(x = .pred, y = price)) +
  geom_point() +
  geom_abline(intercept = 0, col = "red")


houses_plot2 <-
  houses_pred %>%
  select(.pred, price) %>%
  gather(key, value) %>%
  ggplot(aes(x = value, volor = key, fill = key)) +
  geom_density(alpha = .2) +
  labs(x = "", y = "")

houses_plot1 / houses_plot2
```
