---
title: "Model Evaluation"
author: "Arnold Kakaš"
date: "`r Sys.Date()`"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Advertisement data EDA & Price prediction model {.tabset}

### Introduction

In this post I will go through <strong> Exploratory Data Analyses (EDA) </strong> of real estate advertisements data and evaluation of <strong> price prediction model </strong> based on this dataset.

Data is scraped from [Nehnutelnosti](https://www.nehnutelnosti.sk/) website that specializes in real estate listings and services. I will go through the scraping process and initial data cleaning in more details in the next blog post.


### EDA

Loading of libraries. For this part I like to use [packman](https://cran.r-project.org/web/packages/pacman/index.html) package
```{r message=FALSE, warning=FALSE}
# load libs
pacman::p_load(rio, 
               tidyverse,
               tidymodels,
               gt,
               gtsummary,
               GGally,
               patchwork,
               vip,
               janitor,
               sf)#,
               #spdep,
               #rgeos,
               #rgdal,
               #sfdep)
```

<br>
Next step is to load the analysed data. Usually for imports I use [rio](https://cran.r-project.org/web/packages/rio/index.html) package. <br>
As you can see, data is stored in RDS format. I prefer this format due to several reasons: 
* size of the file is lower compared to csv or xlsx, which are usually the ones that we as data analysts are provided with.
* RDS format preserves the entire R object structure, including data frames, matrices, lists, functions, and metadata.Therefore you can save objects like dataframes with factors, trained models, etc. 
* RDS is optimized for reading and writing by the R. Therefore importing or exporting data is very quick.
<br>

Before the EDA, I need to clean up the scraped data.

<br>

I import two datasets. First one is advertisements.RDS file which contains links and basic information from the initial [webpage](https://www.nehnutelnosti.sk/byty/predaj/). I split one of the variables to obtain type of real estate.
This dataframe is joined to second one, advertisements_complete_geocoded.RDS, that contains more detailed information of each of advertisements (these informations are visible after opening the links in first dataframe) and is already geocoded with [tidygeocoder](https://jessecambon.github.io/tidygeocoder/) package using OSM Nominatim API.

<br>

Afterwards follows the <strong> data cleaning </strong> and <strong> data wrangling </strong> using different methods:
* replacing
* filtering
* imputing missing values
* converting to correct data type/creating factors
* removing redundant variables (based on further data analysis, e.g. due to high percentage of missing values or no correlation with price)
* renaming of variables
* grouping
* using geospatial joins
* removing outliers

<br>

Generally this part can be described as <strong> feature engineering </strong>.


```{r echo=TRUE, message=FALSE, warning=FALSE}
# load data for EDA
advertisements <- import("data/advertisements.RDS")
advertisements <- advertisements %>% separate(type_of_real_estate, c("type", "area"), sep = " • ", remove = TRUE) %>% select(link, type)


scraped_cleaned <- import("data/advertisements_complete_geocoded.RDS") %>% 
  left_join(advertisements, by = "link", multiple = "first", keep = FALSE) %>% 
  clean_names() %>%
  mutate(pocet_izieb_miestnosti = as.numeric(pocet_izieb_miestnosti),
         uzit_plocha = str_replace(str_replace(uzit_plocha, ",", "."), " m2", ""),
         energie = str_replace(str_replace(energie, ",", "."), " €/mesiac", ""),
         provizia_zahrnuta_v_cene = str_replace_na(provizia_zahrnuta_v_cene, "Nie"),
         rooms = case_when(type == "1 izbový byt" ~ 1,
                           type == "2 izbový byt" ~ 2,
                           type == "3 izbový byt" ~ 3,
                           type == "4 izbový byt" ~ 4,
                           type == "5 a viac izbový byt" ~ 5,
                           type == "Garsónka" ~ 1,
                           type == "Dvojgarsónka" ~ 2, 
                           .default = NA),
         pocet_izieb_miestnosti = coalesce(pocet_izieb_miestnosti, rooms, pocet_izieb_miestnosti)) %>% 
  mutate_at(c('index_of_living',
              'uzit_plocha',
              'energie',
              'pocet_nadzemnych_podlazi', 
              'podlazie', 
              'pocet_izieb_miestnosti', 
              'rok_vystavby', 
              'rok_poslednej_rekonstrukcie', 
              'pocet_balkonov', 
              'pocet_lodzii'), as.numeric) %>% 
  select(-link, -info_text, -address) %>% 
  filter(pocet_izieb_miestnosti < 10 & !is.na(pocet_izieb_miestnosti)) %>% 
  mutate(
         type = coalesce(type, case_when(pocet_izieb_miestnosti == 1 ~ "1 izbový byt",
                           pocet_izieb_miestnosti == 2 ~ "2 izbový byt",
                           pocet_izieb_miestnosti == 3 ~ "3 izbový byt",
                           pocet_izieb_miestnosti == 4 ~ "4 izbový byt",
                           pocet_izieb_miestnosti >= 5 ~ "5 a viac izbový byt"))) %>% 
  select(-rooms) %>% 
  filter(!(type %in% c("Apartmán", "Mezonet", "Iný byt", "Loft"))) %>% 
  mutate(rooms = case_when(type == "1 izbový byt" ~ 1,
                           type == "2 izbový byt" ~ 2,
                           type == "3 izbový byt" ~ 3,
                           type == "4 izbový byt" ~ 4,
                           type == "5 a viac izbový byt" ~ 5,
                           type == "Garsónka" ~ 1,
                           type == "Dvojgarsónka" ~ 2, 
                           .default = NA)) %>% 
  select(-c(rok_vystavby,
            rok_poslednej_rekonstrukcie,
            typ_konstrukcie,
            pocet_balkonov,
            pocet_lodzii,
            orientacia,
            energie,
            pivnica,
            vytah,
            pocet_izieb_miestnosti,
            pocet_nadzemnych_podlazi,
            podlazie)) %>% 
  rename(index = index_of_living) %>% 
  rename(condition = stav) %>% 
  rename(area = uzit_plocha) %>% 
  rename(provision = provizia_zahrnuta_v_cene) %>%
  rename(certificate = energeticky_certifikat)

scraped_cleaned_wo_geometry <- scraped_cleaned
st_geometry(scraped_cleaned_wo_geometry) <- NULL

number_of_ads <- scraped_cleaned_wo_geometry %>% group_by(name_nsi) %>% tally() %>% arrange(n)

index_district <- scraped_cleaned_wo_geometry %>% 
  filter(!is.na(price)) %>%
  group_by(name_nsi) %>% 
  mutate(index_mean_name_nsi = mean(index, na.rm = TRUE)) %>%
  ungroup() %>%
  select(name_nsi, district, index_mean_name_nsi) %>% 
  distinct() %>% 
  mutate(index_mean_name_nsi = if_else(index_mean_name_nsi > 0, index_mean_name_nsi, NA)) %>% 
  group_by(district) %>% 
  summarize(index_mean_district = mean(index_mean_name_nsi, na.rm = TRUE))

scraped_cleaned <- scraped_cleaned %>% 
  left_join(number_of_ads, by = "name_nsi", keep = FALSE) %>% 
  filter(n > 4) %>% 
  left_join(index_district, by = "district", multiple = "first", keep = FALSE) %>% 
  st_centroid()

districts <- import("data/geospatial_data/districts.RDS")  

scraped_cleaned <- districts %>% 
  st_join(scraped_cleaned, join = st_contains) %>% 
  select(-municipality, -district) %>% 
  rename(district = NAME) %>% 
  mutate(district = as_factor(district),
    condition = as_factor(condition),
    type = as_factor(type),
    provision = as_factor(provision),
    certificate = as_factor(certificate),
    name_nsi = as_factor(name_nsi)
  ) %>% 
  select(-n, -address1, -address2) %>% 
  filter(!is.na(price))


scraped_cleaned_no_outliers <- scraped_cleaned %>% 
  group_by(name_nsi) %>% # group by municipality
  mutate(index = mean(as.numeric(index),na.rm = TRUE), # index of municipality
         index = if_else(index > 0, index, NA), # replace 0 index with NA
         IQR = IQR(price), 
         median = median(price), 
         lower = median - 1.5*IQR, # calculate lower bound
         upper = median + 1.5*IQR  # calculate upper bound
         ) %>% 
  ungroup() %>% 
  filter(price >= lower & price <= upper) %>% # filter out outliers
  select(-lower, -upper, -median, -IQR) # remove variables

st_geometry(scraped_cleaned_no_outliers) <- NULL
```

```{r message=FALSE, warning=FALSE, include=FALSE}
# Remove all dataframes except of scraped_cleaned_no_outliers
rm(list = setdiff(ls(), "scraped_cleaned_no_outliers"))
gc()
```

I like to start the EDA with base summary function.

```{r}
sum_tbl <- summary(scraped_cleaned_no_outliers) %>% 
  as.data.frame()  %>%
  select(- Var1)
  pivot_wider(names_from = Var2, values_from = Freq)
sum_tbl
```


### Final pricing model
Since the goal of this model is to predict price 

The word "Final" in this section may tell you, that there were multiple versions of the model. Indeed, I tried several models - linear regression, random forest and xgboost. 

### Model evaluation


```{r}
# load data for model evaluation
apartments_test <- import("data/apartments_test.RDS")
model <- import("data/model.RDS")
```


```{r}
model %>%
  fit(data = apartments_test) %>%
  pull_workflow_fit() %>%
  vip(num_features = 10,
      geom = "point")
```

```{r}
set.seed(123)
apartments_train_split <- initial_split(apartments_analysis_data, prop = 0.8, strata = price)
results <- last_fit(model, apartments_train_split)
collect_metrics(results) %>%
  mutate(Estimate = round(.estimate, 3),
         Metric = .metric) %>% 
  select(Metric, Estimate) 

```

```{r}
# evaluate
apartments_pred <-
  predict(apartments_xgb_fit, apartments_test) %>%
  bind_cols(apartments_test)

# %>% 
#   mutate(prediction = 10^.pred,
#          real_price = 10^price)

apartments_plot1 <-
  apartments_pred %>%
  ggplot(aes(x = .pred, y = price)) +
  geom_point() +
  geom_abline(intercept = 0, col = "red")


apartments_plot2 <-
  apartments_pred %>%
  select(.pred, price) %>%
  gather(key, value) %>%
  ggplot(aes(x = value, volor = key, fill = key)) +
  geom_density(alpha = .2) +
  labs(x = "", y = "")

apartments_plot1 / apartments_plot2
```